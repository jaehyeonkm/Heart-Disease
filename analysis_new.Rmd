---
title: "Heart Disesase Analysis"
author: "Jae Hyeon Kim (jkim554@illinois.edu)"
date: "11/11/2020"
output:
  html_document: 
    theme: default
    toc: yes
---

```{r, setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
```

***

## Abstract

The reasons for doing this analysis is to create a statistical tool to help determine whether a patient has a heart disease or not. In order to determine if a patient has a heart disease, most of the time it involves going through an invasive medical procedure. As a result we want to create a non-invasive tool for determining heart disease. The methods used in this analysis is calculating the cross-validated validation-estimation accuracy for four models and calculating the test-accuracy for the model with the highest validation-estimation accuracy. We found that the knn model resulted in the highest validation-estimation accuracy. Although the accuracy was not of high value, it is not significantly small. This could mean that with some improvement to the model, it could be used to determine whether a patient might have a potential for heart disease. This statistical tool could be used first, then if a heart disease is suspected, further diagnosis and procedure could be conducted. 

***

## Introduction

One of the leading causes of America is heart disease, as a result it would be useful to have a statistical tool that could be used to predict and detect people with heart disease. The main goal of this analysis is to create a statistical model that could detect whether or not a person has a heart disease within the population where some type of heart condition is suspected. Furthermore, so that a patient does not have to go through an invasive medical procedure in order to determine whether he/she has heart disease. 


***

## Methods

### Data

```{r, load-packages, include = FALSE}
# load packages
library(tidyverse)
library(caret)
library(rpart)
library(rpart.plot)
library(skimr)
```

```{r read-full-data, warning = FALSE, message = FALSE}
# read full data
hd = readr::read_csv("data/hd.csv")
```

The data chosen for this analysis was collected from four location: 

1. Cleveland Clinic Foundation
2. Hungarian Institute of Cardiology, Budapest
3. V.A. Medical Center, Long Beach, CA
4. University Hospital, Zurich, Switzerland

This data consists of 15 variables and 920 observations. The row corresponds to each patient at the hospital, and the columns are expalined in the appendix. The column named "num" is our response variable which is the "angiographic disease status" and it contains five levels, v0 ~ v4. "v0" means there are 0 major vessels with greater than 50% diameter narrowing, indicating no presence of heart disease. "v4" means that there are 4 major vessels with greater than 50%diameter narrowing, which might suggest a very likely presence of heart disease. 

Some processing have made in this data, such as ignoring the NA values in order for this analysis to run smoothly. More details are shown below.

```{r}
# test train split
set.seed(42)
trn_idx = createDataPartition(hd$num, p = 0.80, list = TRUE)
hd_trn = hd[trn_idx$Resample1, ]
hd_tst = hd[-trn_idx$Resample1, ]

# coerce character variables to be factors
hd_trn$num = factor(hd_trn$num)
hd_trn$location = factor(hd_trn$location)
hd_trn$cp = factor(hd_trn$cp)
hd_trn$sex = factor(hd_trn$sex)
hd_trn$fbs = factor(hd_trn$fbs)
hd_trn$restecg = factor(hd_trn$restecg)
hd_trn$exang = factor(hd_trn$exang)

# additional feature engineering
hd_trn[which(hd_trn$chol == 0), ]$chol = NA


na_prop = function(x){
  mean(is.na(x))
}

sapply(hd_trn, na_prop)

# create training dataset without columns containing more than 30% NAs
hd_trn = hd_trn[, !sapply(hd_trn, na_prop) > 0.30]

# look at the data
skim(hd_trn)
```


```{r, echo = FALSE}
# starting exploratory analysis
plot(chol ~ age, data = hd_trn, pch = 20, col = hd_trn$num)
grid()

# can we fit a model? yes
rpart::rpart(num ~ ., data = hd_trn)
```

```{r, echo = FALSE}
# temp remove of na values
hd_trn_full = na.omit(hd_trn)

# estimation - validation split the data
set.seed(42)
est_idx = createDataPartition(hd_trn_full$num, p = 0.80, list = TRUE)
hd_est = hd_trn_full[est_idx$Resample1, ]
hd_val = hd_trn_full[-est_idx$Resample1, ]

# establish first baseline
table(
  actual = hd_val$num,
  predicted = rep("v0", length(hd_val$num))
)

# fit our first model
mod = rpart(num ~ ., data = hd_est)

# establishing first model-based baseline
table(
  actual = hd_val$num,
  predicted = predict(mod, hd_val, type = "class")
)

# calculate baseline accuracy
mean(predict(mod, hd_val, type = "class") == hd_val$num)
```

```{r}
# creating subdata so that I can use glm function
hd_new = hd %>% 
  mutate(num = ifelse(num == "v0", "0", "1"))

# coerce character variables to be factors
hd_new$num = factor(hd_new$num)
hd_new$location = factor(hd_new$location)
hd_new$cp = factor(hd_new$cp)
hd_new$sex = factor(hd_new$sex)
hd_new$fbs = factor(hd_new$fbs)
hd_new$restecg = factor(hd_new$restecg)
hd_new$exang = factor(hd_new$exang)

# test train split
set.seed(42)
trn_new_idx = createDataPartition(hd_new$num, p = 0.80, list = TRUE)
hd_new_trn = hd_new[trn_new_idx$Resample1, ]
hd_new_tst = hd_new[-trn_new_idx$Resample1, ]

# additional feature engineering
hd_new_trn[which(hd_new_trn$chol == 0), ]$chol = NA

# create training dataset without columns containing more than 30% NAs
hd_new_trn = hd_new_trn[, !sapply(hd_new_trn, na_prop) > 0.30]

# temp remove of na values
hd_new_trn_full = na.omit(hd_new_trn)

# estimation - validation split the data
set.seed(42)
est_new_idx = createDataPartition(hd_new_trn_full$num, p = 0.80, list = TRUE)
hd_new_est = hd_new_trn_full[est_new_idx$Resample1, ]
hd_new_val = hd_new_trn_full[-est_new_idx$Resample1, ]
```

### Modeling 

There are 4 different models made: decision tree, knn, boosted model, and random forest model. The training data is split further into estimation and validation data in order to calculate the validation accuracy of each model. Cross-validation using 5 folds is used for each of the model. 

```{r, echo = FALSE}
# temp remove any observation with any missing data
hd_trn_full = na.omit(hd_trn)
hd_tst_full = na.omit(hd_tst)
# estimation - validation split the data
set.seed(42)
est_idx = createDataPartition(hd_trn_full$num, p = 0.80, list = TRUE)
hd_est = hd_trn_full[est_idx$Resample1, ]
hd_val = hd_trn_full[-est_idx$Resample1, ]
```

```{r}
# setup 5 fold cross validation
cv_5 = trainControl(method = "cv", number = 5)

hd_tree_tune = expand.grid(
  cp = c(0, 0.0001, 0.001, 0.01, 0.1, 1)
)

hd_knn_tune = expand.grid(
  k = 1:100
)

hd_gbm_tune = expand.grid(
  n.trees = c(50, 100, 150, 200),
  interaction.depth = 1:3,
  shrinkage = c(0.1, 0.3),
  n.minobsinnode = c(5, 10)
)

hd_tree_mod = train(
  form = num ~ .,
  data = hd_est,
  method = "rpart",
  trControl = cv_5,
  tuneLength = 10
  )

hd_knn_mod = train(
  form = num ~ .,
  data = hd_est,
  method = "knn",
  trControl = cv_5,
  tuneGrid = hd_knn_tune
  )

hd_gbm_mod = train(
  form = num ~ .,
  data = hd_est,
  method = "gbm",
  trControl = cv_5,
  tuneGrid = hd_gbm_tune,
  verbose = FALSE
  )

hd_rf_mod = train(
  form = num ~ .,
  data = hd_est,
  method = "rf",
  trControl = cv_5,
  verbose = FALSE
  )

# test-train accuracy using hd_knn_mod
hd_knn_mod_trn = train(
  form = num ~ .,
  data = hd_trn_full,
  method = "knn",
  trControl = cv_5,
  tuneLength = 53
  )
```

```{r}
# fit glm model
hd_glm = glm(num ~ ., data = hd_new_est, family = "binomial")

# obtain prediction using glm for test data
prob_glm = predict(hd_glm, hd_new_val, type = "response")
pred_glm = factor(ifelse(prob_glm > 0.5, "1", "0"))

# template Confusion Matrix
tp = sum(hd_new_val$num == "1" & pred_glm == "1")
fp = sum(hd_new_val$num == "0"  & pred_glm == "1")
fn = sum(hd_new_val$num == "1" & pred_glm == "0")
tn = sum(hd_new_val$num == "0"  & pred_glm == "0")

# checking if the above calculation is correct
sum(c(tp = tp, fp = fp, fn = fn, tn = tn)) == nrow(hd_new_val)
```

***

## Results

```{r}
confusionMatrix(hd_tree_mod)

confusionMatrix(hd_gbm_mod)
```

```{r, warning = FALSE}
val_acc_base = mean(predict(mod, hd_val, type = "class") == hd_val$num)
val_acc_tree = mean(predict(hd_tree_mod, data = hd_val, type = "raw") == hd_val$num)
val_acc_knn = mean(predict(hd_knn_mod, data = hd_val, type = "raw") == hd_val$num)
val_acc_gbm = mean(predict(hd_gbm_mod, data = hd_val, type = "raw") == hd_val$num)
val_acc_rf = mean(predict(hd_rf_mod, data = hd_val, type = "raw") == hd_val$num)

tst_acc_knn = mean(predict(hd_knn_mod, data = hd_tst_full, type = "raw") == hd_tst_full$num)

data.frame(val_acc_base, val_acc_tree, val_acc_knn, val_acc_gbm, val_acc_rf, tst_acc_knn)
```

The estimation validation accuracy for each of the model are shown above. Among them, it seems the knn model had the highest validation accuracy of 0.4964371, among the four models. Furthermore, the tuning parameter of k = 53 was used as the final value. As a result, the test accuracy for this model was calculated with a value of 0.4774347. Although this may not seem to be a highly accurate model, the "best" model among the four models seems to be the knn model. 

Sensitivity (True Positive Rate) = TP / P
Specificity (True Negative Rate) = TN / N
Precision (Positive Predictive Value) = TP / (TP + FP)

```{r}
# Confusion Matrix of glm function
c(tp = tp, fp = fp, fn = fn, tn = tn)

# Sensitivity
sens = tp / (tp + fn)

# Specificity = True Negative Rate 
spec = tn / (tn + fp)

# Precision
prec = tp / (tp + fp)

# F1_score
F1_score = 2 * (prec * sens)/(prec + sens)

data.frame(sens, spec, prec, F1_score)
```


***

## Discussion

Something to remember about this model is that the population is based on people who are in suspicion of heart disease or experiencing some type of heart condition. As a result if this model were to be applied to a wider population, there is a chance that the model might suggest that people without heart condition do have heart condition. An average individual might care about these results is that if the accuracy of the models tested were high enough, one could use this model to figure out if he/she has heart disease without having to go through invasive medical procedure. Furthermore, if improvements are made to this model then this model could be used in various hospitals in order to figure out a patient's potential of having heart disease. 

***

## Changelog

Another subset has been made for this new analysis `hd_new`. I created this subset to focus on the false negatives and in order to test a new model using glm function. I mutated the original data so that `v0` - no presence of heart disease is classified as "0" and `v1` ~ `v4` which does indicate a presence of heart disease to be classified as "1". Then I ran a binary classification using the glm function to see if this function helps with minimizing the false negative of the classification. Then I calculated the sensitivity, specificity, precision, and the F1 score of this model. 

***


## Appendix

The variables used:

- `age` - age in years
- `sex` - sex (1 = male; 0 = female)
- `cp` - chest pain type
- `trestbps` - resting blood pressure (in mm Hg on admission to the hospital)
- `chol` - serum cholesterol in mg/dl
- `fbs` - (fasting blood sugar > 120 mg/dl) ( 1 = true; 0 = false)
- `restecg` - resting electrocardiographic results 
- `thalach` - maximum heart rate acheived
- `exang` - exercise induced angina (1 = yes; 0 = no)
- `oldpeak` - ST depression induced by exercise relative to rest
- `slope` - the slope of the peak exercise ST segment
- `ca` - number of major vessels (0-3) colored by floursopy
- `thal` - 3 = normal; 6 = fixed defect; 7 = reversible defect
- `num` - presence of heart disease 

